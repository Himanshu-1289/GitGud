{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a3811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "from typing import TypedDict\n",
    "\n",
    "class ExtractCode(TypedDict):\n",
    "    '''\n",
    "    Formatted Output for llm\n",
    "    Attributes:\n",
    "    code (str): code generated by the llm\n",
    "    language (str): language of the code generated by the llm \n",
    "    '''\n",
    "    extracted_code: str = Field(\n",
    "    ...,\n",
    "    description=\"Solution of the code\",\n",
    "    )\n",
    "    language: str | None = Field(\n",
    "    ..., description=\"Programming language of the code\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f18fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdecda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated,Dict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"State class containing messages and extracted code.\"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38326f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class AgentDeps:\n",
    "    api_key : str\n",
    "    http_client : Any\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e59a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type, Any, Literal, get_type_hints\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.managed import RemainingSteps\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "class MessagesWithSteps(MessagesState):\n",
    "    remaining_steps: RemainingSteps\n",
    "\n",
    "\n",
    "def end_or_reflect(state: MessagesWithSteps) -> Literal[END, \"graph\"]:\n",
    "    if state[\"remaining_steps\"] < 5:\n",
    "        return END\n",
    "    if len(state[\"messages\"]) == 0:\n",
    "        return END\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        return \"graph\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "def create_reflection_graph(\n",
    "    graph: CompiledStateGraph,\n",
    "    reflection: CompiledStateGraph,\n",
    "    state_schema: Optional[Type[Any]] = None,\n",
    "    config_schema: Optional[Type[Any]] = None,\n",
    ") -> StateGraph:\n",
    "    _state_schema = state_schema or graph.builder.schema\n",
    "\n",
    "    if \"remaining_steps\" in _state_schema.__annotations__:\n",
    "        raise ValueError(\n",
    "            \"Has key 'remaining_steps' in state_schema, this shadows a built in key\"\n",
    "        )\n",
    "\n",
    "    if \"messages\" not in _state_schema.__annotations__:\n",
    "        raise ValueError(\"Missing required key 'messages' in state_schema\")\n",
    "\n",
    "    class StateSchema(_state_schema):\n",
    "        remaining_steps: RemainingSteps\n",
    "\n",
    "    rgraph = StateGraph(StateSchema, config_schema=config_schema)\n",
    "    rgraph.add_node(\"graph\", graph)\n",
    "    rgraph.add_node(\"reflection\", reflection)\n",
    "    rgraph.add_edge(START, \"graph\")\n",
    "    rgraph.add_edge(\"graph\", \"reflection\")\n",
    "    rgraph.add_conditional_edges(\"reflection\", end_or_reflect)\n",
    "    return rgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27254b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CODE_SYSTEM_PROMPT = os.getenv(\"CODE_SYSTEM_PROMPT\")\n",
    "JUDGE_SYSTEM_PROMPT = os.getenv(\"JUDGE_SYSTEM_PROMPT\")\n",
    "GROQ_API_TOKEN = os.getenv(\"GROQ_API_KEY\")\n",
    "COMPILER_URL = os.getenv(\"COMPILER_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74f8c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from httpx import AsyncClient\n",
    "\n",
    "agent_deps = AgentDeps(api_key=GROQ_API_TOKEN,http_client=AsyncClient)\n",
    "\n",
    "code_model_settings = {\"temperature\": 0.3}\n",
    "judge_model_settings = {\"temperature\": 0.7}\n",
    "\n",
    "code_agent : Agent[None,ExtractCode] = Agent(\n",
    "            model=\"groq:llama3-8b-8192\",\n",
    "            system_prompt=CODE_SYSTEM_PROMPT,\n",
    "            model_settings=code_model_settings,\n",
    "            output_type = ExtractCode,\n",
    "        )\n",
    "\n",
    "judge_agent : Agent[None,str] = Agent(\n",
    "            model=\"groq:meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "            system_prompt=JUDGE_SYSTEM_PROMPT,\n",
    "            model_settings=judge_model_settings,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebddfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def call_model(state: Dict[str,Any]):\n",
    "    code = code_agent.run_sync(state[\"messages\"][-1].content)\n",
    "    state[\"messages\"].append(AIMessage(code.output[\"extracted_code\"]))\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c237cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def compiler(state : Dict[str,Any]):\n",
    "    response = requests.post(COMPILER_URL,\n",
    "                            json={\n",
    "                                \"code\": state[\"messages\"][-1].content,\n",
    "                                \"language\": \"python\",\n",
    "                            },\n",
    "                        )\n",
    "    result = response.json()\n",
    "    if response.status_code == 200:\n",
    "        output = result.get(\"output\")\n",
    "    else:\n",
    "        output = result\n",
    "    judgement = judge_agent.run_sync(state[\"messages\"][-1].content+\"\\n\\n\\nOutput:\\n\\n\"+output)\n",
    "    state[\"messages\"].append(HumanMessage(judgement.output))\n",
    "    return state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49160170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "agent_graph = (\n",
    "            StateGraph(State)\n",
    "            .add_node(call_model, \"call_model\")\n",
    "            .add_edge(\"call_model\", END)\n",
    "            .add_edge(START,\"call_model\")\n",
    "            .compile()\n",
    "        )\n",
    "\n",
    "judge_graph = (\n",
    "            StateGraph(State)\n",
    "            .add_node(compiler,\"compiler\")\n",
    "            .add_edge(\"compiler\",END)\n",
    "            .add_edge(START,\"compiler\")\n",
    "            .compile()\n",
    ")\n",
    "\n",
    "reflection_agent = create_reflection_graph(agent_graph,judge_graph).compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539c4d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def twoSum(nums: list[int], target: int) -> list[int]:\n",
      "    \"\"\"Returns the indices of the two numbers in the list that add up to the target.\n",
      "    Args:\n",
      "    - nums: A list of integers.\n",
      "    - target: The target sum.\n",
      "    Returns:\n",
      "    - A list containing the indices of the two numbers that add up to the target.\n",
      "    - If no solution is found, an empty list is returned.\"\n",
      "    if not isinstance(nums, list) or len(nums) < 2:\n",
      "        raise ValueError('Input must be a list with at least two elements')\n",
      "    if not all(isinstance(num, int) for num in nums):\n",
      "        raise ValueError('All elements in the list must be integers')\n",
      "    if not isinstance(target, int):\n",
      "        raise ValueError('Target must be an integer')\n",
      "    num_indices = {}\n",
      "    for i, num in enumerate(nums):\n",
      "        complement = target - num\n",
      "        if complement in num_indices:\n",
      "            return [num_indices[complement], i]\n",
      "        num_indices[num] = i\n",
      "    return []\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Given an array of integers nums and an integer target, \"\n",
    "                \"return indices of the two numbers such that they add up to target. \"\n",
    "                \"You may assume that each input would have exactly one solution, \"\n",
    "                \"and you may not use the same element twice. Return the answer in any order.\\n\\n\"\n",
    "                \"Example:\\nInput: nums = [2, 7, 11, 15], target = 9\\nOutput: [0, 1]\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "result = reflection_agent.invoke(state)\n",
    "print(result[\"messages\"][-2].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8352785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
